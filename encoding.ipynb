{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Install and Import"},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install category_encoders","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nimport hashlib\nimport numpy as np\nimport pandas as pd\nimport category_encoders\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport patsy\n\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Unsupervised"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = pd.Series(['2_Bachelors', '1_High-School', '4_PhD', '3_Masters'], name = 'x')\ny = pd.Series([65000, 54000, 80000, 72000], name = 'y')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Ordinal Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_encoding = x.replace(dict(zip(sorted(set(x)), range(1, len(sorted(set(x))) + 1))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_encoding.name = 'OrdinalEncoding'\nshow = pd.concat([x, ordinal_encoding], axis = 1)\nshow","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Count Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"count_encoding = x.replace(x.value_counts().to_dict())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_encoding.name = 'CountEncoding'\nshow = pd.concat([x, count_encoding], axis = 1)\nshow","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. One-Hot Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"one_hot_encoding = ordinal_encoding.apply(lambda e: pd.Series(np.diag(np.ones(len(set(x))))[e - 1].astype(int)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from psutil import virtual_memory\n\nmem = virtual_memory()\n\nmem.total / 1024 ** 3, mem.used / 1024 ** 3, mem.available / 1024 ** 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one_hot_encoding.columns = sorted(set(x))\nshow = pd.concat([x, ordinal_encoding, one_hot_encoding], axis = 1)\nshow.columns = [['x', 'OrdinalEncoding'] + ['OneHotEncoding'] * len(set(x)), [''] * 2 + list(one_hot_encoding.columns)]\nshow","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.concat([x, y], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sm.OLS(y, pd.concat([pd.Series(1, index = x.index, name = 'intercept'), one_hot_encoding], axis = 1)).fit().params","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Sum Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"sum_encoding = one_hot_encoding.iloc[:, :-1].apply(lambda row: row if row.sum() == 1 else row.replace(0, -1), axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum_encoding","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_encoding.columns = sorted(set(x))[:-1]\nshow = pd.concat([x, ordinal_encoding, sum_encoding], axis = 1)\nshow.columns = [['x', 'OrdinalEncoding'] + ['SumEncoding'] * (len(set(x)) - 1), [''] * 2 + sorted(set(x))[:-1]]\nshow","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.concat([x, y], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sm.OLS(\n    endog = y, \n    exog = pd.concat([pd.Series(1, index = x.index, name = 'intercept'), sum_encoding], axis = 1)\n).fit().params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"a -> 10.5 - 5.5 = 5\n\nb -> 10.5 - 0.5 = 10\n\nc -> 10.5 - 3.5 = 7\n\nd -> 10.5 - (-5.5 -.5 -3.5) = 20"},{"metadata":{},"cell_type":"markdown","source":"## 5. Backward-Difference"},{"metadata":{"trusted":true},"cell_type":"code","source":"backward_difference_encoding = ordinal_encoding.apply(\n    lambda oe: pd.Series([i / len(set(x)) for i in range(1, oe)] + [- i / len(set(x)) for i in range(len(set(x)) - oe, 0, -1)])\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert (backward_difference_encoding == category_encoders.BackwardDifferenceEncoder().fit_transform(X = x).drop('intercept', axis = 1).values).all().all()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"backward_difference_encoding.columns = sorted(set(x))[1:]\nshow = pd.concat([x, ordinal_encoding, backward_difference_encoding], axis = 1)\nshow.columns = [['x', 'OrdinalEncoding'] + ['BackwardDifferenceEncoding'] * len(sorted(set(x))[1:]), [''] * 2 + sorted(set(x))[1:]]\nshow","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sm.OLS(\n    endog = y, \n    exog = pd.concat([pd.Series(1, index = x.index, name = 'intercept'), backward_difference_encoding], axis = 1)\n).fit().params","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"b -> 10 - 5 = 5\n\nc -> 7 - 10 = -3\n\nd -> 20 - 7 = 13"},{"metadata":{},"cell_type":"markdown","source":"## 6. Helmert Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"helmert_encoding = ordinal_encoding.apply(\n    lambda oe: pd.Series([0] * (oe - 2) + ([oe - 1] if oe > 1 else []) + [-1] * (len(set(x)) - oe))\n).div(pd.Series(range(2,len(set(x)) + 1)))\n# https://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert (helmert_encoding == category_encoders.HelmertEncoder().fit_transform(X = x).drop('intercept', axis = 1).values / np.arange(2, len(set(x)) + 1)).all().all()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"helmert_encoding.columns = sorted(set(x))[1:]\nshow = pd.concat([x, ordinal_encoding, helmert_encoding], axis = 1)\nshow.columns = [['x', 'OrdinalEncoding'] + ['HelmertEncoding'] * helmert_encoding.shape[1], [''] * 2 + sorted(set(x))[1:]]\nshow","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sm.OLS(\n    endog = y, \n    exog = pd.concat([pd.Series(1, index = x.index, name = 'intercept'), helmert_encoding], axis = 1)\n).fit().params.round(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"b -> 10 - 5 = 5\n\nc -> 7 - np.mean([5, 10, 7]) = -0.5\n\nd -> 20 - np.mean([5, 10, 7]) = 12.66667"},{"metadata":{},"cell_type":"markdown","source":"## 7. Polynomial Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"def do_polynomial_encoding(order):\n    # https://github.com/pydata/patsy/blob/master/patsy/contrasts.py\n    n = len(set(x))\n    scores = np.arange(n)\n    scores = np.asarray(scores, dtype=float)\n    scores -= scores.mean()\n    raw_poly = scores.reshape((-1, 1)) ** np.arange(n).reshape((1, -1))\n    q, r = np.linalg.qr(raw_poly)\n    q *= np.sign(np.diag(r))\n    q /= np.sqrt(np.sum(q ** 2, axis=1))\n    # q[:, 0] = 1\n    q = q[:, 1:]\n    return q[order - 1]\n\npolynomial_encoding = ordinal_encoding.apply(lambda oe: pd.Series(do_polynomial_encoding(oe)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert (polynomial_encoding == category_encoders.PolynomialEncoder().fit_transform(X = x).drop('intercept', axis = 1).values).all().all()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"polynomial_encoding.columns = ['degree' + str(i) for i in range(1, polynomial_encoding.shape[1] + 1)]\nshow = pd.concat([x, ordinal_encoding, polynomial_encoding], axis = 1)\nshow.columns = [['x', 'OrdinalEncoding'] + ['PolynomialEncoding'] * polynomial_encoding.shape[1], \n                [''] * 2 + list(polynomial_encoding.columns)]\nshow","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sm.OLS(\n    endog = y, \n    exog = pd.concat([pd.Series(1, index = x.index, name = 'intercept'), polynomial_encoding], axis = 1)\n).fit().params.round(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 8. Binary Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_base = ordinal_encoding.apply(lambda oe: str(bin(oe))[2:].zfill(len(bin(len(set(x)))) - 2))\nbinary_encoding = binary_base.apply(lambda bb: pd.Series(list(bb))).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert (binary_encoding == category_encoders.BinaryEncoder().fit_transform(X = x).values).all().all()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_encoding.columns = ['dim' + str(i) for i in range(binary_encoding.shape[1], 0, -1)]\nshow = pd.concat([x, ordinal_encoding, binary_base, binary_encoding], axis = 1)\nshow.columns = [\n    ['x', 'OrdinalEncoding', 'binary_base'] + ['BinaryEncoding'] * binary_encoding.shape[1], \n    [''] * 3 + list(binary_encoding.columns)\n]\nshow","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 9. Base N Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"def int2base(n, base):\n    assert n > 0\n    out = ''\n    while n:\n        out += str(int(n % base))\n        n //= base\n    return out[::-1]\n\nbase = 3\n\nbase_n = ordinal_encoding.apply(lambda oe: int2base(n = oe, base = base))\nbase_n_encoding = base_n.apply(lambda bn: pd.Series(list(bn.zfill(base_n.apply(len).max())))).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert (base_n_encoding == category_encoders.BaseNEncoder(base = base).fit_transform(X = x).iloc[:,1:].values).all().all()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_n_encoding.columns = ['dim' + str(i) for i in range(base_n_encoding.shape[1], 0, -1)]\nshow = pd.concat([x, ordinal_encoding, base_n, base_n_encoding], axis = 1)\nshow.columns = [\n    ['x', 'OrdinalEncoding', 'base_{}'.format(base)] + ['BaseNEncoding'] * base_n_encoding.shape[1], \n    [''] * 3 + list(base_n_encoding.columns)\n]\nshow","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 10. Hashing Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"def do_hash(string, output_dimension):\n    hasher = hashlib.new('sha256')\n    hasher.update(bytes(string, 'utf-8'))\n    string_hashed = hasher.hexdigest()\n    string_hashed_int = int(string_hashed, 16)\n    string_hashed_int_remainder = string_hashed_int % output_dimension\n    return string_hashed, string_hashed_int, string_hashed_int_remainder\n\noutput_dimension = 10\n\nhashing = x.apply(\n    lambda string: pd.Series(do_hash(string, output_dimension), \n        index = ['x_hashed', 'x_hashed_int', 'x_hashed_int_remainder']))\n\nhashing_encoding = hashing['x_hashed_int_remainder'].apply(lambda rem: pd.Series(np.diag(np.ones(output_dimension))[rem]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert (hashing_encoding == category_encoders.HashingEncoder(hash_method = 'sha256', n_components = output_dimension).fit_transform(X = x).values).all().all()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hashing_encoding.columns = ['dim' + str(i) for i in range(hashing_encoding.shape[1], 0, -1)]\nshow = pd.concat([x, hashing, hashing_encoding], axis = 1)\nshow.columns = [\n    ['x', 'x_hashed', 'x_hashed_int', 'x_hashed_int_remainder'] + ['HashingEncoding'] * hashing_encoding.shape[1], \n    [''] * 4 + list(hashing_encoding.columns)\n]\nshow","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sm.OLS(\n    endog = y, \n    exog = pd.concat([pd.Series(1, index = x.index, name = 'intercept'), hashing_encoding], axis = 1)\n).fit().params.round(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Supervised"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = pd.Series(['a', 'a', 'b', 'b', 'b', 'b'])\ny = pd.Series([ 1, 2, 3, 4, 5, 6])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 11. Target Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"count_encoding = x.replace(y.groupby(x).count())\ny_grand_mean = x.apply(lambda l: y.mean())\ny_level_mean = x.replace(y.groupby(x).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_encoding = dict()\n\nfor smoothing in [0, 1, 10]:\n    weight = 1 / (1 + np.exp(-(count_encoding - 1) / smoothing))\n    target_encoding[smoothing] = y_level_mean * weight + y_grand_mean * (1 - weight)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for sm, te in target_encoding.items():\n    assert (te == category_encoders.TargetEncoder(smoothing = sm).fit_transform(X = x, y = y).iloc[:, 0]).all()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show = pd.concat([x, y, y_level_mean, y_grand_mean] + [target_encoding[i] for i in target_encoding.keys()], axis = 1)\nshow.columns = [\n    ['x', 'y', 'y_level_mean', 'y_grand_mean'] + ['TargetEncoding'] * len(target_encoding), \n    [''] * 4 + ['smoothing={}'.format(sm) for sm in target_encoding.keys()]\n]\nshow","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 12. MEstimate Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"count_encoding = x.replace(y.groupby(x).count())\ny_grand_mean = x.apply(lambda l: y.mean())\ny_level_mean = x.replace(y.groupby(x).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m_estimate_encoding = dict()\n\nfor m in [0, 1, 10]:\n    m_estimate_encoding[m] = (y_level_mean * count_encoding + y_grand_mean * m) / (count_encoding + m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for m, te in m_estimate_encoding.items():\n    assert (te == category_encoders.MEstimateEncoder(m = m).fit_transform(X = x, y = y).iloc[:, 0]).all()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show = pd.concat([x, y, count_encoding, y_level_mean, y_grand_mean] + [m_estimate_encoding[i] for i in m_estimate_encoding.keys()], axis = 1)\nshow.columns = [\n    ['x', 'y', 'CountEncoding', 'y_level_mean', 'y_grand_mean'] + ['MEstimateEncoding'] * len(m_estimate_encoding), \n    [''] * 5 + ['m={}'.format(m) for m in m_estimate_encoding.keys()]\n]\nshow","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 13. James-Stein Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = pd.Series(['a', 'a', 'b', 'b', 'c', 'c', 'd', 'd'], name = 'x')\ny = pd.Series([ 1, 2, 3, 4, 5, 6, 7, 15], name = 'y')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_level_mean = x.replace(y.groupby(x).mean())\ny_level_var = x.replace(y.groupby(x).var()).fillna(0)\nweight = (y_level_var / (y.var() + y_level_var) * (len(set(x)) - 3) / (len(set(x)) - 1)).clip(lower=0, upper=1)\njames_stein_encoding = y_level_mean * (1 - weight) + y.mean() * weight","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert (james_stein_encoding == category_encoders.JamesSteinEncoder().fit_transform(X = x, y = y).iloc[:, 0]).all()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show = pd.concat([x, y, y_level_mean, y_level_var, pd.Series(y.mean(), index = x.index), pd.Series(y.var(), index = x.index), weight, james_stein_encoding], axis = 1)\nshow.columns = ['x', 'y', 'y_level_mean', 'y_level_var', 'y.mean()', 'y.var()', 'weight', 'JamesSteinEncoding']\nshow","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 14. GLMM Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = smf.mixedlm(formula = 'y ~ 1', data = y.to_frame(), groups = x).fit()\nintercept = pd.Series(model.params['Intercept'], index = x.index)\nrandom_effect = x.replace({k: float(v) for k, v in model.random_effects.items()})\nglmm_encoding = intercept + random_effect","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert (random_effects == category_encoders.GLMMEncoder().fit_transform(X = x, y = y).iloc[:, 0]).all()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show = pd.concat([x, y, intercept, random_effect, glmm_encoding], axis = 1)\nshow.columns = ['x', 'y', 'intercept', 'random_effect', 'GLMMEncoding']\nshow","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 15. WOE Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = pd.Series(['a','a','b','b','b','b'], name = 'x')\ny = pd.Series([0,1,0,0,0,1], name = 'y')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_level_ones = x.replace(y.groupby(x).apply(lambda l: (l == 1).sum()))\ny_level_zeros = x.replace(y.groupby(x).apply(lambda l: (l == 0).sum()))\ny_ones = (y == 1).sum()\ny_zeros = (y == 0).sum()\nnominator = y_level_ones / y_ones\ndenominator = y_level_zeros / y_zeros\nwoe_encoder = np.log(nominator / denominator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert (woe_encoder == category_encoders.WOEEncoder(regularization = 0).fit_transform(X = x, y = y).iloc[:, 0]).all()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show = pd.concat([x, y, y_level_ones, y_level_zeros, pd.Series(y_ones, index = x.index), pd.Series(y_zeros, index = x.index), nominator, denominator, woe_encoder], axis = 1)\nshow.columns = ['x', 'y', 'y_level_ones', 'y_level_zeros', 'y_ones', 'y_zeros','nominator', 'denominator', 'WOEEncoding']\nshow","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## 16. Leave One Out Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = pd.Series(['a','a','b','b','b','b'], name = 'x')\ny = pd.Series([1,2,3,4,5,6], name = 'y')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_level_except_self = x.to_frame().apply(lambda row: y[x == row['x']].drop(row.name).to_list(), axis = 1)\nleave_one_out_encoding = y_level_except_self.apply(np.mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert (leave_one_out_encoding == category_encoders.LeaveOneOutEncoder().fit_transform(X = x, y = y).iloc[:, 0]).all()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show = pd.concat([x, y, y_level_except_self, leave_one_out_encoding], axis = 1)\nshow.columns = ['x', 'y', 'y_level_except_self', 'LeaveOneOutEncoding']\nshow['LeaveOneOutEncoding'] = show['LeaveOneOutEncoding'].round(2)\nshow","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## 17. CatBoost Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = pd.Series(['a','a','b','b','b','b'], name = 'x')\ny = pd.Series([1,2,3,4,5,6], name = 'y')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = 1\ny_level_before_self = x.to_frame().apply(lambda row: y[(x == row['x']) & (y.index < row.name)].to_list(), axis = 1)\ncatboost_encoding = y_level_before_self.apply(lambda l: (sum(l) + y.mean() * a) / (len(l) + a))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert (catboost_encoding == category_encoders.CatBoostEncoder().fit_transform(X = x, y = y).iloc[:, 0]).all()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show = pd.concat([x, y, pd.Series(y.mean(), index = x.index), y_level_before_self, catboost_encoding], axis = 1)\nshow.columns = ['x', 'y', 'y_mean', 'y_level_before_self', 'CatBoostEncoding']\nshow","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# End"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Unsupervised:\n\n- Backward Difference Contrast [2][3]\n- BaseN [6]\n- Binary [5]\n- Count [10]\n- Hashing [1]\n- Helmert Contrast [2][3]\n- Ordinal [2][3]\n- One-Hot [2][3]\n- Polynomial Contrast [2][3]\n- Sum Contrast [2][3]\n\n# Supervised:\n\n- CatBoost [11]\n- Generalized Linear Mixed Model [12]\n- James-Stein Estimator [9]\n- LeaveOneOut [4]\n- M-estimator [7]\n- Target Encoding [7]\n- Weight of Evidence [8]"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder_names = [class_ for class_ in dir(category_encoders) if class_[0].isupper()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder_names = [class_ for class_ in dir(category_encoders) if class_[0].isupper()]\nfor en in encoder_names:\n    print(en)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder_names = [class_ for class_ in dir(category_encoders) if class_[0].isupper()]\ndf = pd.DataFrame(index = encoder_names)\n\nx = pd.Series(['a','b','b','c','c','c'])\ny = pd.Series([1,2,3,4,5,6])\ny_bin = pd.Series([0,0,1,0,1,1])\n\nfor encoder_name in encoder_names:\n    print(encoder_name)\n    exec('enc = category_encoders.{}()'.format(encoder_name))\n    try:\n        x_enc = enc.fit_transform(x)\n        df.loc[encoder_name, 'type'] = 'unsupervised'\n    except:\n        try:\n            x_enc = enc.fit_transform(x, y)\n            df.loc[encoder_name, 'type'] = 'supervised'\n        except:\n            x_enc = enc.fit_transform(x, y_bin)\n            df.loc[encoder_name, 'type'] = 'supervised'\n\n    df.loc[encoder_name, 'output_dimension'] = 'single' if x_enc.shape[1] == 1 else 'multiple'\n    df.loc[encoder_name, 'mapping'] = 'unique' if (~pd.concat([x, x_enc], axis = 1).duplicated()).sum() == len(set(x)) else 'not unique'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_excel('encoders.xlsx')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.concat([x, x_enc], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder_names = [class_ for class_ in dir(category_encoders) if class_[0].isupper()]\n\nfor encoder_name in encoder_names:\n    print(encoder_name)\n    #exec('print(category_encoders.{}.__doc__)'.format(encoder_name))\n    try:    \n        exec('enc = category_encoders.{}()'.format(encoder_name))\n        x = pd.Series(['a','b','b','c','c','c'])\n        y = pd.Series([1,2,3,4,5,6])\n        x_enc = enc.fit_transform(x, y = y)\n        print(x_enc.shape[1] == 1)\n        print(x_enc)\n    except Exception as e:\n        print('Exception:', e)\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder_names = [class_ for class_ in dir(category_encoders) if class_[0].isupper()]\n\nfor encoder_name in encoder_names:\n    print(encoder_name)\n    try:    \n        exec('enc = category_encoders.{}()'.format(encoder_name))\n        x = pd.Series(['a','b','b','c','c','c'])\n        y = pd.Series([1,2,3,4,5,6])\n        x_enc = enc.fit_transform(x, y = y)\n        print(x_enc)\n    except Exception as e:\n        print('Exception:', e)\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = pd.Series(['a','a','b','b','c','c','c','c'])\nx_enc = BackwardDifferenceEncoder().fit_transform(x)\nx_enc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_enc.sum(axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"series = pd.Series(['a','b','b','c','c','c'])\ny = pd.Series([1,2,3,4,5,6])\n\n\ncategory = pd.Categorical(series)\n\ncategories = category.categories\ncodes = category.codes.copy()\n\ncodes[codes == -1] = len(categories)\ncategories = np.append(categories, np.nan)\n\nreturn_map = pd.Series(dict([(code, category) for code, category in enumerate(categories)]))\n\nresult = y.groupby(codes).agg(['sum', 'count'])\nreturn_ = result.rename(return_map)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}